#! /usr/bin/env python

#
# Imports
#

from flask import Flask
from flask import render_template
from flask import json
import metadata
import sys
import time
import os

app = Flask(__name__)

#
# check input and get commandline args
#
try: analysisfolder = metadata.AnalysisFolder(sys.argv[1])
except IndexError: sys.stderr.write('please supply a commandline on format:\nwfaViewerServer <analysis-output-folder>\n');sys.exit()
app.analysisfolder = analysisfolder

#
# check analysis folder
#
if not analysisfolder.checkIntegrity() == 'PASS': print analysisfolder.checkIntegrity()+'\nERROR: Now exiting'

#
# create a logfile
#
logfile = open(analysisfolder.logpath+'/'+time.strftime("%y%m%d-%H:%M:%S",time.localtime())+'_wfaViewerServer','w',1)
logfile.write('cmd: '+' '.join(sys.argv)+'\n')
analysisfolder.logfile = logfile

def createStaticFiles(app):
    
    #
    # Imports
    #
    import sys
    import os
    import seqdata    
    import operator
    
    pathToStatic = '/'.join(os.path.realpath(sys.argv[0]).split('/')[:-1])+'/static'
    if not os.path.isdir(pathToStatic): os.mkdir(pathToStatic)
    
    #insert sizes
	
    #
    # open connection to database
    #
    app.analysisfolder.database.getConnection()

    before = app.analysisfolder.settings.mapqCutOff
    for mapq in xrange(50):
        app.analysisfolder.settings.mapqCutOff=mapq
        readPairs = app.analysisfolder.database.c.execute('SELECT insertSize FROM reads WHERE mapQR1>=? AND mapQR2>=?',(app.analysisfolder.settings.mapqCutOff,app.analysisfolder.settings.mapqCutOff,))
        isizeDict = {}
        insertSizeCSV=open(pathToStatic+'/insersizes.'+str(app.analysisfolder.settings.mapqCutOff)+'.csv','w')
        insertSizeCSV.write('iSize,count\n')
        while True:
            
            rows = readPairs.fetchmany()#size=readPairs.arraysize)
            
            if not rows: break
            
            for row in rows:
                insertSize = row[0]
                try: isizeDict[insertSize]+=1
                except KeyError:isizeDict[insertSize]=1
        
        for insertSize, count in sorted(isizeDict.iteritems(), key=operator.itemgetter(0)): insertSizeCSV.write( str(insertSize)+','+str(count)+'\n')
    app.analysisfolder.settings.mapqCutOff=before
    
    app.analysisfolder.database.commitAndClose()    

def indexForeachCluster(clusterId):
    from seqdata import BarcodeClusterer, BarcodeCluster
    cluster = BarcodeCluster(clusterId,app.analysisfolder)
    cluster.loadClusterInfo()
    #cluster.loadReadPairs()
    cluster.minMAPQ = 20
    return cluster

@app.route("/")
def start():
    page =  """<!DOCTYPE HTML>
    <html lang="en-US">
	<head>
	    <meta charset="UTF-8">
	    <meta http-equiv="refresh" content="1;url=index.html">
	    <script type="text/javascript">
		window.location.href = "index.html"
	    </script>
	    <title>Page Redirection</title>
	</head>
	<body>
	    If you are not redirected automatically, follow <a href='index.html'>this link</a>
	</body>
    </html>"""
    return page

@app.route("/index.html")
def index():
    
    app.analysisfolder.logfile.write('Generating index.html ...\n')
    
    from seqdata import BarcodeClusterer, BarcodeCluster
    from misc import thousandString, percentage
    import os
    import operator
    outStr = ''
    outStr += '<html>'
    outStr += """<head><style>
        body {
            background-color:white
            font-family : Arial,"Myriad Web",Verdana,Helvetica,sans-serif;
        }
        h1   {color:black}
        p    {color:green}
        
        table, th, td {
            border: 1px solid black;
            border-collapse: collapse;
            
            font-size : 12;
        }
        th {
            text-align: center;
            background-color:darkgray;
            color:white;
            border: 1px solid black;
        }
        table {border-spacing: 1px;}
        th,td {padding: 5px;}
        td {text-align: center;}
    </style></head>"""
    outStr += '<body>'

    outStr += '<div style="background-color:black;color:white;text-align:left;padding:5px;position:relative;width:100%">'
    outStr += '<h2>'+'&nbsp&nbsp&nbsp&nbsp'+'Summary of analysis at '+str(os.path.abspath(app.analysisfolder.path))+':</h2>'
    outStr += '</div>'

    outStr += '<div style="line-height:30px;background-color:#e1e1e1;width:100%;height:50px;float:left;padding:20px;text-align:center;top;position:relative;top:0; ">'
    outStr += '<svg height="50" width="200"><circle cx="21" cy="21" r="20" stroke="black" stroke-width="1" fill="gray" /><text x="50" y="25">wfaChecker</text></svg>'
    outStr += '<svg height="50" width="200"><circle cx="21" cy="21" r="20" stroke="black" stroke-width="1" fill="gray" /><text x="50" y="25">barcodeClustrer</text></svg>'
    outStr += '<svg height="50" width="200"><circle cx="21" cy="21" r="20" stroke="black" stroke-width="1" fill="gray" /><text x="50" y="25">clustersMapper</text></svg>'
    outStr += '<svg height="50" width="200"><circle cx="21" cy="21" r="20" stroke="black" stroke-width="1" fill="gray" /><text x="50" y="25">reStructure</text></svg>'
    outStr += '</div>'
    outStr += '<div style="line-height:30px;background-color:#eeeeee;width:700px;height:50000px;float:left;padding:20px;position:relative;top:0; ">'
    outStr += '<h2>Stats:</h2>'
    outStr += 'Total read pairs: '+thousandString(app.analysisfolder.results.totalReadCount)+'<br>\n'
    outStr += 'Minimum R1 length: '+str(app.analysisfolder.results.minR1readLength)+'<br>\n'
    outStr += 'Minimum R2 length: '+str(app.analysisfolder.results.minR2readLength)+'<br>\n'
    outStr += 'Reads has illumina adapter content: '+thousandString(app.analysisfolder.results.readPairsAreIlluminaAdapters)+' ('+str(percentage(app.analysisfolder.results.readPairsAreIlluminaAdapters,app.analysisfolder.results.totalReadCount))+'% of total)<br>\n'
    outStr += '<br>\n'
    
    outStr += 'Construct type dictionary: '+'<br>\n'
    #for what, count in eval(app.analysisfolder.results.constructTypes).iteritems():
    if app.analysisfolder.results.constructTypes:
        for what, count in sorted(eval(app.analysisfolder.results.constructTypes).iteritems(), key=operator.itemgetter(1))[::-1]:
            outStr += '&nbsp&nbsp&nbsp&nbsp'+what+' => '+str(percentage(count,app.analysisfolder.results.totalReadCount))+'%, ('+thousandString(count)+')<br>\n'
    else:outStr += 'No Data Available<br>\n'
    outStr += '<br>\n'
    
    outStr += 'Barcodes match DBS pattern:<br>\n'
    if app.analysisfolder.results.readsWithDbsPatternMatch:
        tmp = eval(app.analysisfolder.results.readsWithDbsPatternMatch)
        outStr += '&nbsp&nbsp&nbsp&nbsp'+'barcode does not exist => '+str(percentage(tmp[None],app.analysisfolder.results.totalReadCount))+'%, ('+thousandString(tmp[None])+')<br>\n'
        outStr += '&nbsp&nbsp&nbsp&nbsp'+'barcode does not match => '+str(percentage(tmp[False],app.analysisfolder.results.totalReadCount))+'%, ('+thousandString(tmp[False])+')<br>\n'
        outStr += '&nbsp&nbsp&nbsp&nbsp'+'barcode match DBS pattern=> '+str(percentage(tmp[True],app.analysisfolder.results.totalReadCount))+'%, ('+str(percentage(tmp[True],int(app.analysisfolder.results.totalReadCount)-int(tmp[None])))+'% of has barcode,'+thousandString(tmp[True])+')<br>\n'
    outStr += '<br>\n'
    outStr += 'Read pairs has a barcode: '+thousandString(app.analysisfolder.results.readPairsHasBarcode)+'<br>\n'
    outStr += 'Unique barcodes: '+thousandString(app.analysisfolder.results.uniqueBarcodeSequences)+'<br>\n'
    outStr += 'Barcode clusters found: '+thousandString(app.analysisfolder.results.barcodeClusterCount)+'<br>\n'
    outStr += 'Barcode clusters are singletons: '+thousandString(app.analysisfolder.results.singeltonBarcodeClusters)+'<br>\n'+'<br>\n'
    outStr += 'Bowtie2 alignment Rate: '+str(app.analysisfolder.results.bt2AlignmentRate)+'%<br>\n'
    outStr += 'Percentage of SE alignments with mapq >= 20: '+str(app.analysisfolder.results.alignmentRateQ20)+'%<br>\n'+'<br>\n'
    outStr += '<br>\n'
    outStr += '</div>'
    
    outStr += '<div style="width:350px;float:left;padding:20px; ">'
    outStr += '<h2>List of clusters:</h2>'
    if app.analysisfolder.results.barcodeClusterCount:
        barcodeClusterer = BarcodeClusterer(app.analysisfolder)
        import multiprocessing
        #poolOfProcesses = multiprocessing.Pool(int(app.analysisfolder.settings.parallelProcesses),maxtasksperchild=10000)
        #parallelResults = poolOfProcesses.imap_unordered(indexForeachCluster,barcodeClusterer.getBarcodeClusterIds(shuffle=False,byMixedClusterReadCount=False),chunksize=1)
        #parallelResults = poolOfProcesses.imap(indexForeachCluster,barcodeClusterer.getBarcodeClusterIds(shuffle=False,byMixedClusterReadCount=False),chunksize=1)
        outStr += '<table>'
        outStr += '<tr>' 
        outStr += '<th>clusterID</th>'
        outStr += '<th>barcode</th>'
        outStr += '<th>readcount</th>'
        outStr += '<th>sameCrom</th>'
        outStr += '<th>chrom</th>'
        outStr += '<th>duplicate</th>'
    #    outStr += '<th>pos R1</th>'
    #    outStr += '<th>pos R2</th>'
    #    outStr += '<th>insertsize</th>'
    #    outStr += '<th>mapQ</th>'
    #    outStr += '<th>CIGAR</th>'
        outStr += '</tr>' 
        counter = 0
        sameChrom = 0
        pcrDup = 0
        totalReadPairCount=0
        for clusterId in barcodeClusterer.getBarcodeClusterIds(shuffle=False,byMixedClusterReadCount=False):
            cluster = indexForeachCluster(clusterId)
        #for cluster in parallelResults:
            counter += 1
            if counter == 1000: break
            #if not cluster.allreadssamechrom or (cluster.allreadssamechrom==True and cluster.allreadssamepos): continue
            outStr += '<tr>'
            outStr += '<td><a href="cluster'+str(cluster.id)+'">'+str(cluster.id)+'</a></td>'
            outStr += '<td><a href="cluster'+str(cluster.id)+'"><font face="Courier">'+str(cluster.barcodeSequence)+'</font></a></td>\n'
            outStr += '<td><a href="cluster'+str(cluster.id)+'">'+str(cluster.readPairCount)+'</a></td>\n'
            totalReadPairCount += cluster.readPairCount
            outStr += '<td><a href="cluster'+str(cluster.id)+'">'
            if True:#cluster.allreadssamechrom:
                sameChrom += 1
                outStr += '<font color="green">'
            else:
                outStr += '<font color="red">'
            #outStr += str(cluster.allreadssamechrom)+'</a></td>\n'
	    outStr += str('NA')+'</a></td>\n'
            outStr += '<td><a href="cluster'+str(cluster.id)+'">'
            if False:#cluster.allreadssamechrom:
		outStr += str(cluster.chromosome)+'</a></td>\n'#readPairs[0].refNameR1)+'</a></td>\n'
            else:
		outStr += 'NA</a></td>\n'
            outStr += '<td><a href="cluster'+str(cluster.id)+'">'
            if False:#not (cluster.allreadssamechrom==True and cluster.allreadssamepos) and cluster.allreadssamepos != None:
                outStr += '<font color="green">'
            else:
                pcrDup += 1
                outStr += '<font color="red">'
            #outStr += str(cluster.allreadssamechrom==True and cluster.allreadssamepos)+'</a></td>\n'
	    outStr += 'NA'+'</a></td>\n'

    
            outStr += '</tr>'
        #poolOfProcesses.close();print 'Closing'
        #poolOfProcesses.terminate();print 'terminating'
        #poolOfProcesses.join();print 'joining'
        outStr += '<tr>'
        outStr += '<td>'+str(counter)+'</td>'
        outStr += '<td><font face="Courier">NA</font></td>\n'
        outStr += '<td>'+str(totalReadPairCount)+'</td>\n'
        outStr += '<td>'+str(percentage(sameChrom,counter))+'%</td>\n'
        outStr += '<td><font face="Courier">NA</font></td>\n'
        outStr += '<td>'+str(percentage(pcrDup,counter))+'%</td>\n'
    
        outStr += '</table>'
    outStr += '</div>'
    
    app.analysisfolder.logfile.write('index.html generated.\n')
    return outStr

@app.route('/cluster<cluster_id>')
@app.route('/cluster<cluster_id>/read<readnumber>')
def cluster(cluster_id, readnumber=None):

    import time
    starttime = time.time()
    print 'Creating per cluster page for cluster '+str(cluster_id)
    app.analysisfolder.logfile.write('Creating per cluster page for cluster '+str(cluster_id)+' ... '+'\n')
    from seqdata import BarcodeCluster
    from misc import thousandString
    from misc import percentage
    import pysam

    outStr = ''
    outStr += '<html>'
    outStr += """<head><style>
        body {
            background-color:white
            font-family : Arial,"Myriad Web",Verdana,Helvetica,sans-serif;
        }
        h1   {color:black}
        p    {color:green}
        
        table, th, td {
            border: 1px solid black;
            border-collapse: collapse;
            
            font-size : 12;
        }
        th {
            text-align: center;
            background-color:darkgray;
            color:white;
            border: 1px solid black;
        }
        table {border-spacing: 1px;}
        th,td {padding: 5px;}
        td {text-align: center;}
    </style></head>"""
    outStr += '<body>'

    cluster = BarcodeCluster(int(cluster_id),app.analysisfolder)
    app.analysisfolder.logfile.write('Loading reads for cluster '+str(cluster_id)+' ... '+'\n')
    cluster.loadClusterInfo()
    outStr += 'cluster id='+str(cluster_id)+' with barcode '+str(cluster.barcodeSequence)+' has '+str(cluster.readPairCount)+' read pairs'+'<br><br>\n'
    cluster.loadReadPairs()
    print 'creatingBamfile...'
    app.analysisfolder.logfile.write('Creating bamfiles for cluster_'+str(cluster_id)+' ... '+'\n')
    cluster.createBamFile()
    app.analysisfolder.logfile.write('Bamfiles ready for cluster_'+str(cluster_id)+'.'+'\n')

    tableStr = '<table>'
    tableStr += '<tr>' 
    tableStr += '<th>header</th>'
    tableStr += '<th>flags</th>'
    tableStr += '<th>refchrom R1</th>'
    tableStr += '<th>refchrom R2</th>'
    tableStr += '<th>pos R1</th>'
    tableStr += '<th>pos R2</th>'
    tableStr += '<th>insertsize</th>'
    tableStr += '<th>mapQ</th>'
    tableStr += '<th>CIGAR</th>'
    tableStr += '<th>ProperPair</th>'
    tableStr += '</tr>'
    #for pair in cluster.readPairs:
    #    tableStr += '<tr>'
    #    tableStr += '<td>'
    #    if pair.mapQR1 < 20 or pair.mapQR2 < 20 or pair.mapQR1 == '*' or pair.mapQR2 == '*': tableStr += '<font color="red">'
    #    else: tableStr += '<font color="green">'
    #    tableStr += pair.header+ '</td>'
    #    tableStr += '<td>'+str(pair.mappingFlagR1.flag)+' '+str(pair.mappingFlagR2.flag)+'</td>'
    #    tableStr += '<td>'+str(pair.refNameR1)+'</td>'
    #    tableStr += '<td>'+str(pair.refNameR2)+'</td>'
    #    if pair.refPosR1: tableStr += '<td>'+thousandString(pair.refPosR1)+'</td>'
    #    else:tableStr += '<td>'+str(pair.refPosR1)+'</td>'
    #    if pair.refPosR2: tableStr += '<td>'+thousandString(pair.refPosR2)+'</td>'
    #    else:tableStr += '<td>'+str(pair.refPosR2)+'</td>'
    #    tableStr += '<td>'+str(pair.insertSize)+'</td>'
    #    tableStr += '<td>'+str(pair.mapQR1)+' '+str(pair.mapQR2)+'</td>'
    #    tableStr += '<td>'+str(pair.cigarR1)+' '+str(pair.cigarR2)+'</td>'
    #    tableStr += '<td>'+str(pair.mappingFlagR1.properpair)+'</td>'
    #    tableStr += '</tr>'
    #tableStr += '</table>'

    bamfile =  pysam.Samfile(app.analysisfolder.temp+'/cluster_'+str(cluster.id)+'.markedDuplicates.bam')
    positions = {}
    chromSizes = {}
    tableStrDup =''
    duplicates = 0
    tmptotal = 0
    goodrows = ''
    duplicateAndUnmappedRows = ''
    for chrom in bamfile.header['SQ']:
        chromSizes[chrom['SN']]=chrom['LN']
    for alignedReadRead in bamfile:
        
	if alignedReadRead.is_read1: # just check read one to do paired data
	     
	    #mate = bamfile.mate(alignedReadRead)
	    #
	    # filters
	    #
	    goodMapping = bool(alignedReadRead.mapq >= app.analysisfolder.settings.mapqCutOff and not alignedReadRead.is_unmapped and not alignedReadRead.mate_is_unmapped)
	    
	    if goodMapping:
		RNAME = bamfile.getrname(alignedReadRead.tid)
		tmptotal += 1
		if alignedReadRead.is_duplicate: duplicates += 1
		else:
		    try: positions[RNAME].append(min(alignedReadRead.pos,alignedReadRead.pnext))
		    except KeyError: positions[RNAME] = [min(alignedReadRead.pos,alignedReadRead.pnext)]
	    else: RNAME = 'NA'

            row = '<tr><td>'
            if not (not alignedReadRead.is_duplicate and goodMapping):
		row += '<font color="red">'
            else: row += '<font color="green">'
            row += alignedReadRead.qname+ '</td>'
            row += '<td>'+str(alignedReadRead.flag)+'</td>'
            row += '<td>'+str(RNAME)+'</td>'
            row += '<td>'+str('NA')+'</td>'
            if alignedReadRead.pos: row += '<td>'+thousandString(alignedReadRead.pos)+'</td>'
            else:row += '<td>'+str(alignedReadRead.pos)+'</td>'
            if alignedReadRead.pnext: row += '<td>'+thousandString(alignedReadRead.pnext)+'</td>'
            else:row += '<td>'+str(alignedReadRead.pnext)+'</td>'
            row += '<td>'+str(alignedReadRead.isize)+'</td>'
            row += '<td>'+str(alignedReadRead.mapq)+' '+str('mate.mapq')+'</td>'
            row += '<td>'+str(alignedReadRead.cigar)+' '+str('mate.cigar')+'</td>'
            row += '<td>'+str(alignedReadRead.is_proper_pair)+'</td>'
            row += '</tr>'
	    
	    if alignedReadRead.is_duplicate or alignedReadRead.is_unmapped or alignedReadRead.mate_is_unmapped:
		duplicateAndUnmappedRows += row
	    else: goodrows += row

    tableStr+= goodrows
    #tableStr+= '<tr>'+ '<td>'+'<font color="green">NOWBADREADS</td><td>FLAG</td><td>RNAME</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr>'
    tableStr+=duplicateAndUnmappedRows
    tableStr += '</table>'
    outStr += str(percentage(duplicates,tmptotal))+'% of the reads are duplicates ('+str(duplicates)+' of '+str(tmptotal)+' mapped reads mapq GT '+str(app.analysisfolder.settings.mapqCutOff)+').<br>\n'

    #
    # Make plot
    #
    import matplotlib.pyplot as plt
    import operator
    for chrom, data in positions.iteritems():
        binSize = int(int(chromSizes[chrom])/100)
        plots = []
        fig, axes = plt.subplots(1, sharex=True)
        chrom=str(chrom)
        plots.append(axes.hist(data,range(0,int(chromSizes[chrom]),binSize),label='chrom '+str(chrom)))#,histtype='step'))
        handles, labels = axes.get_legend_handles_labels()
        hl = sorted(zip(handles, labels), key=operator.itemgetter(1))
        handles2, labels2 = zip(*hl)
        axes.legend(handles2, labels2,loc=0,fontsize='small')
        axes.set_xlabel('coordinate')
        axes.set_ylabel('# Number of reads')
        axes.set_xlim([0,int(chromSizes[chrom])])
        y_max = axes.get_ylim()[1]
        x_max = axes.get_xlim()[1]
        
        #
        # add text to graph
        #
        #axes.text(int(round(x_max*0.6,0)),int(round(y_max*0.85,0)),'Average = '+str(round(np.average(sizes),2))+' pL')
        #axes.text(int(round(x_max*0.6,0)),int(round(y_max*0.85-1*int(round(y_max*0.05,0)),0)),'Median = '+str(round(np.median(sizes),2))+' pL')
        #axes.text(int(round(x_max*0.6,0)),int(round(y_max*0.85-2*int(round(y_max*0.05,0)),0)),'Standard deviation = '+str(round(np.std(sizes),2)))
        #axes.text(int(round(x_max*0.6,0)),int(round(y_max*0.85-3*int(round(y_max*0.05,0)),0)),'droplets in 50uL = '+str(round( 50/np.average(sizes) ,2))+'M')
        #axes.text(int(round(x_max*0.6,0)),int(round(y_max*0.85-4*int(round(y_max*0.05,0)),0)),'Max = '+str(round(max(sizes),2))+' pL')
        #axes.text(int(round(x_max*0.6,0)),int(round(y_max*0.85-5*int(round(y_max*0.05,0)),0)),'Min = '+str(round(min(sizes),2))+' pL')
        #axes.text(int(round(x_max*0.6,0)),int(round(y_max*0.85-6*int(round(y_max*0.05,0)),0)),''+str(int(round(len(sizes),2)))+' droplets identified')
        
        #
        # save to pdf
        #
        #plt.savefig('histogram2_sizes.pdf',dpi=300,bbox_inches='tight')
        plt.savefig(app.analysisfolder.temp+'/cluster_'+str(cluster.id)+'.histogram.'+chrom+'.png',dpi=300,bbox_inches='tight')
    
    outStr += tableStr
    outStr += '</body></html>\n'
    app.analysisfolder.logfile.write('Page for cluster '+str(cluster_id)+' generated in '+str(round(time.time()-starttime,2))+'seconds '+'\n')
    return outStr

if __name__ == "__main__":
#    createStaticFiles(app)
    app.run(host='0.0.0.0',port=5000,debug=True)

