#! /usr/bin/env python

import sys

def main(): 
    #
    # Imports
    #
    import metadata
    import time
    from seqdata import BarcodeClusterer
    from misc import Progress
    import multiprocessing
    import sqlite3
    
    #
    # check input and get commandline args
    #
    try: analysisfolder = metadata.AnalysisFolder(sys.argv[1])
    except IndexError: sys.stderr.write('please supply a commandline on format:\analyseClusters <analysis-output-folder> [reanalyze=bool]\n');sys.exit()
    try:
	if eval(sys.argv[2].split('=')[1])==True:reAnalyze(analysisfolder)
    except IndexError: pass

    #
    # check analysis folder
    #
    if not analysisfolder.checkIntegrity() == 'PASS': print analysisfolder.checkIntegrity()+'\nERROR: Now exiting'

    #
    # create a logfile
    #
    logfile = open(analysisfolder.logpath+'/'+time.strftime("%y%m%d-%H:%M:%S",time.localtime())+'_analyseClusters.log.txt','w',1)
    logfile.write('cmd: '+' '.join(sys.argv)+'\n')
    analysisfolder.logfile = logfile

    #
    # restructuring the data
    #
    if False:#not analysisfolder.database.datadropped:
	logfile.write('Restructuring database ... \n')
	barcodeClusterer = BarcodeClusterer(analysisfolder)
	barcodeClusterer.fillReadsDb()
	logfile.write('Dropping data ... \n')
	analysisfolder.database.dropReadColumns()
	logfile.write('done. \n')

    progress = Progress(analysisfolder.results.barcodeClusterCount,logfile=analysisfolder.logfile, unit='clusters',printint=1)
    updateChunk = []

    runInParallel = True
    if runInParallel:
	poolOfProcesses = multiprocessing.Pool(int(analysisfolder.settings.parallelProcesses),maxtasksperchild=100000000)
	parallelResults = poolOfProcesses.imap_unordered(foreachCluster,cluster_generator(analysisfolder),chunksize=1)
	for cluster in parallelResults:
	    updateChunk = forResultingCluster(progress,cluster,updateChunk)

    else:
        for cluster in cluster_generator(analysisfolder):
	    cluster = foreachCluster(cluster)
	    updateChunk = forResultingCluster(progress,cluster)

    logfile.write('analyseClusters FINISHED\n')

def reAnalyze(analysisfolder):
    analysisfolder.database.getConnection()
    analysisfolder.database.c.execute('UPDATE barcodeClusters SET analyzed=?',(False,))
    analysisfolder.database.commitAndClose()

def forResultingCluster(progress,cluster,updateChunk):
    if cluster.analyzed: updateChunk.append(cluster.updatedb(doUpdate=False,returnTuple=True))
    progress.update()
    if len(updateChunk) >= 1000:
	updateClusterChunk(cluster.analysisfolder,updateChunk)
	updateChunk = []
    return updateChunk

def cluster_generator(analysisfolder):
    
    from seqdata import BarcodeCluster
    from seqdata import BarcodeClusterer
    
    barcodeClusterer = BarcodeClusterer(analysisfolder)
    for cluster_id in barcodeClusterer.getBarcodeClusterIds(shuffle=True,byMixedClusterReadCount=True):
#    for cluster_id in barcodeClusterer.getBarcodeClusterIds(shuffle=False,byMixedClusterReadCount=False):
	cluster = BarcodeCluster(int(cluster_id), analysisfolder)
	#if cluster.readPairCount < 10: continue
	yield cluster

def foreachCluster(cluster):
    cluster.loadClusterInfo()
    if not cluster.analyzed and cluster.readPairCount >= cluster.analysisfolder.settings.minPairsPerCluster:
	cluster.analyze()
	cluster.removeAllFiles()
    elif cluster.analyzed:
	cluster.analyzed = False;
	print cluster.id,'already analyzed'
    elif cluster.readPairCount < cluster.analysisfolder.settings.minPairsPerCluster:
	cluster.analyzed = True;
	cluster.annotations['LowReadCount']=True;
	print cluster.id,' low read count'
    return cluster

def updateClusterChunk(analysisfolder,chunk):
    with analysisfolder.database.lock:
	analysisfolder.database.writeInProgress.value = True
	import sqlite3
	import time
	updated = False
	while not updated:
	    try: 
		analysisfolder.database.getConnection()
		analysisfolder.database.c.execute('PRAGMA table_info(barcodeClusters)')
		columnNames = [col[1] for col in analysisfolder.database.c.fetchall()]
		if 'constructTypes' not in columnNames:
		    try: analysisfolder.logfile.write('Creating columns in table barcodeClusters in database \n')
		    except ValueError: pass
		    analysisfolder.database.getConnection()
		    analysisfolder.database.c.execute("alter table barcodeClusters add column constructTypes string")
		    analysisfolder.database.c.execute("alter table barcodeClusters add column readPairsInBamFile integer")
		    analysisfolder.database.c.execute("alter table barcodeClusters add column mappedSEReads integer")
		    analysisfolder.database.c.execute("alter table barcodeClusters add column SEreadsPassMappingQualityFilter integer")
		    analysisfolder.database.c.execute("alter table barcodeClusters add column goodReadPairs integer")
		    analysisfolder.database.c.execute("alter table barcodeClusters add column duplicateReadPairs integer")
		    analysisfolder.database.c.execute("alter table barcodeClusters add column goodReadPairPositions string")
		    analysisfolder.database.c.execute("alter table barcodeClusters add column htmlTable string")
		    analysisfolder.database.c.execute("alter table barcodeClusters add column analyzed BOOLEAN")
		analysisfolder.database.c.executemany('UPDATE barcodeClusters SET annotations=?, constructTypes=?,readPairsInBamFile=?, mappedSEReads=?, SEreadsPassMappingQualityFilter=?, goodReadPairs=?, duplicateReadPairs=?, goodReadPairPositions=?, htmlTable=?, analyzed=? WHERE clusterId=?', chunk)
		analysisfolder.database.commitAndClose()
		analysisfolder.database.writeInProgress.value = False
		updated = True
		print 'updated ',len(chunk),'clusters', updated,'(',','.join([str(x[-1]) for x in chunk]),')'
	    except sqlite3.OperationalError: time.sleep(1)



if __name__ == "__main__": main()