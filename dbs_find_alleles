#! /usr/bin/env python

import sys

def main(): 
    #
    # Imports
    #
    import metadata
    import time
    from seqdata import BarcodeClusterer
    from misc import Progress
    import multiprocessing
    import sqlite3
    import json, ast
    import os

    #
    # check input and get commandline args
    #
    try:
        analysisfolder = metadata.AnalysisFolder(sys.argv[1])
        analysisfolder.readindexTsv()
        if analysisfolder.settings.temp: analysisfolder.copy_to_temp()

    except IndexError: sys.stderr.write('please supply a commandline on format:\n'+os.path.basename(__file__)+' <analysis-output-folder>\n');sys.exit()

    #
    # check analysis folder
    #
    if not analysisfolder.checkIntegrity() == 'PASS': print analysisfolder.checkIntegrity()+'\nERROR: Now exiting'

    #
    # create a logfile
    #
    logfile = open(analysisfolder.logpath+'/'+time.strftime("%y%m%d-%H:%M:%S",time.localtime())+'_find_alleles.log.txt','w',1)
    logfile.write('cmd: '+' '.join(sys.argv)+'\n')
    analysisfolder.logfile = logfile

    #
    # check if the target region bedfile is defined
    #
    if not analysisfolder.settings.targetRegionBed or not os.path.exists(analysisfolder.settings.targetRegionBed):
        msg = 'WARNING: cant find the target definition bed file!!\n'
        msg+= '(If run is not targeted you can safely ignore this message).\n'
        sys.stderr.write(msg);
        logfile.write(msg)
     
    #
    # Do the work here!!
    #
    app = ClusterAllelComparer(analysisfolder)
    app.run()
    
    if analysisfolder.database_in_temp: analysisfolder.copy_from_temp()
        
    logfile.write('find_alleles FINISHED\n')

class ClusterAllelComparer():
    """ comparison machine for looking identifying, comparing and finiding support for alleles in the data """
    
    def __init__(self,analysisfolder):
        
        # set conectionn to the analysisfolder
        self.analysisfolder = analysisfolder
        
        # define initial values for variables to be used later
        self.high_qualitty_cluster_ids = None # list for holding the ids of high quality clusters
        self.high_qualitty_barcode_clusters = []
        
        #
        # containers for barcode_clusters:
        #
        self.potential_seed_clusters = [] # container for barcode clusters with full target coverage that will be used as potential seeds for allele clusters
        self.barcode_clusters_by_read_count = {}
        self.barcode_clusters_by_id = {}
        self.singleton_barcode_clusters_ids = {}
        self.perfect_barcode_clusters = {}
        self.low_read_count_cluster_ids = []
        self.cluster_trash_bin = {
            'non clonal':{
                'individual_id':{},
                'hetro_bases':{}
            },
            'Low_read_count':{},
            'No_similarity_to_allele_cluster':{},
            'matching_more_than_1_allele_cluster':{},
        }

    def load_all_barcode_clustes_to_memory_2ndVersion(self):

        msg = 'Loading barcode clusters to memory ...\n'
        self.analysisfolder.logfile.write(msg); sys.stdout.write(msg)
        
        self.read_count_cut_off = 20#self.analysisfolder.setting.minPairsPerCluster
        
        import misc
        p = misc.Progress(self.analysisfolder.results.barcodeClusterCount-self.analysisfolder.results.singeltonBarcodeClusters, unit='barcode clusters loaded',printint=5, logfile=sys.stdout)

        from seqdata import BarcodeCluster
        import sqlite3
        self.analysisfolder.database.getConnection()
        #info = self.analysisfolder.database.c.execute('SELECT clusterId, clusterTotalReadCount, clusterBarcodeSequence, annotations, constructTypes, readPairsInBamFile, mappedSEReads, SEreadsPassMappingQualityFilter, goodReadPairs, duplicateReadPairs, targetInfo, individual_ID_dictionary, analyzed, hetrozygous_positions, high_quality_cluster FROM barcodeClusters WHERE clusterTotalReadCount>1')
        info = self.analysisfolder.database.c.execute('SELECT clusterId, clusterTotalReadCount, readPairsList, clusterBarcodeSequence, annotations, constructTypes, readPairsInBamFile, mappedSEReads, SEreadsPassMappingQualityFilter, goodReadPairs, duplicateReadPairs, targetInfo, individual_ID_dictionary, analyzed, hetrozygous_positions, high_quality_cluster FROM barcodeClusters')
        for                                                  (clusterId, clusterTotalReadCount, readPairsList, clusterBarcodeSequence, annotations, constructTypes, readPairsInBamFile, mappedSEReads, SEreadsPassMappingQualityFilter, goodReadPairs, duplicateReadPairs, targetInfo, individual_ID_dictionary, analyzed, hetrozygous_positions, high_quality_cluster) in info:
            readBarcodeIdentitiesList, clusterBarcodeQuality, contigSequencesList, goodReadPairPositions, htmlTable = '[]', None, None, None, None
            #readPairsList = '[]'
            if clusterId == None: continue
            if clusterTotalReadCount == 1: continue
            barcode_cluster = BarcodeCluster(clusterId,self.analysisfolder)
            barcode_cluster.setValues(clusterId,clusterTotalReadCount,readPairsList,readBarcodeIdentitiesList,clusterBarcodeSequence,clusterBarcodeQuality,contigSequencesList,annotations,constructTypes, readPairsInBamFile, mappedSEReads, SEreadsPassMappingQualityFilter, goodReadPairs, duplicateReadPairs, goodReadPairPositions,targetInfo,individual_ID_dictionary,htmlTable,analyzed, hetrozygous_positions, high_quality_cluster)

            if barcode_cluster.readPairCount > self.read_count_cut_off:
                self.barcode_clusters_by_id[barcode_cluster.id] = barcode_cluster
                try:             self.barcode_clusters_by_read_count[barcode_cluster.readPairCount].append(barcode_cluster)
                except KeyError: self.barcode_clusters_by_read_count[barcode_cluster.readPairCount]   =   [barcode_cluster]
                if barcode_cluster.high_quality_cluster and barcode_cluster.hetrozygous_positions == 0: self.perfect_barcode_clusters[barcode_cluster.id] = barcode_cluster
            else:
                self.low_read_count_cluster_ids.append( (barcode_cluster.id, barcode_cluster.readPairCount) )

            p.update()

        self.analysisfolder.database.commitAndClose()
        msg = 'barcode clusters loaded.\n'
        self.analysisfolder.logfile.write(msg); sys.stdout.write(msg)

    def load_all_barcode_clustes_to_memory(self):

        msg = 'Loading barcode clusters to memory ...\n'
        self.analysisfolder.logfile.write(msg); sys.stdout.write(msg)
        
        self.read_count_cut_off = 20#self.analysisfolder.setting.minPairsPerCluster
        
        import misc
        p = misc.Progress(self.analysisfolder.results.barcodeClusterCount-self.analysisfolder.results.singeltonBarcodeClusters, unit='barcode clusters loaded',printint=5, logfile=sys.stdout)
        
        #for barcode_cluster in self.analysisfolder.database.getAllClustersLoaded(self.analysisfolder, cluster_id_max=100, cluster_id_min=10, skip_singletons=True):#, skip_htmlTable=True):
        for barcode_cluster in self.analysisfolder.database.getAllClustersLoaded(self.analysisfolder, cluster_id_max=False, cluster_id_min=False, skip_singletons=True, skip_htmlTable=True):
            if barcode_cluster.readPairCount > 1:
                
                if barcode_cluster.readPairCount > self.read_count_cut_off:
                    self.barcode_clusters_by_id[barcode_cluster.id] = barcode_cluster
                    try:             self.barcode_clusters_by_read_count[barcode_cluster.readPairCount].append(barcode_cluster)
                    except KeyError: self.barcode_clusters_by_read_count[barcode_cluster.readPairCount]   =   [barcode_cluster]
                    if barcode_cluster.high_quality_cluster and barcode_cluster.hetrozygous_positions == 0: self.perfect_barcode_clusters[barcode_cluster.id] = barcode_cluster
                else:
                    self.low_read_count_cluster_ids.append( (barcode_cluster.id, barcode_cluster.readPairCount) )
            
            elif barcode_cluster.readPairCount == 1:
                self.singleton_barcode_clusters_ids[barcode_cluster.id] = True
                msg = 'Error: just got a singleton barcode cluster -> Exiting.\n'
                self.analysisfolder.logfile.write(msg); sys.stderr.write(msg)
                sys.exit()
            else:
                msg = 'Error: just got a zero read cluster -> Exiting.\n'
                self.analysisfolder.logfile.write(msg); sys.stderr.write(msg)
                sys.exit()

            p.update()

        msg = 'barcode clusters loaded.\n'
        self.analysisfolder.logfile.write(msg); sys.stdout.write(msg)

    def get_initial_stats(self):
        """
            function for printing some initial statistics
        """

        import misc

        msg  = '\n#\n# Initial status:\n#\n'

        self.analysisfolder.database.getConnection()
        msg += misc.thousandString(self.analysisfolder.results.totalReadCount)+' read pairs were added to the analysis.\n'
        barcode_cluster_read_counts = [i[0] for i in self.analysisfolder.database.c.execute('SELECT clusterTotalReadCount FROM barcodeClusters').fetchall()]
        sum_of_read_counts = sum(barcode_cluster_read_counts)
        msg += 'Out of these '+misc.thousandString(sum_of_read_counts)+' read pairs ('+str(misc.percentage(sum_of_read_counts,self.analysisfolder.results.totalReadCount))+'%) were clustered to '+misc.thousandString(self.analysisfolder.results.barcodeClusterCount)+' barcode_clusters.\n'

        msg += 'Out of the barcode clusters were '+misc.thousandString(len(self.barcode_clusters_by_id))+' loaded to this analysis ('+str(misc.percentage(len(self.barcode_clusters_by_id),self.analysisfolder.results.barcodeClusterCount)) +'%)'
        read_pairs_in_analysis = sum([barcode_cluster.readPairCount for barcode_cluster in self.barcode_clusters_by_id.values()])
        msg += ' they consist of '+misc.thousandString(read_pairs_in_analysis)+' read pairs ('+str(misc.percentage(read_pairs_in_analysis,self.analysisfolder.results.totalReadCount))+'% of total read pairs)\n'
        msg += 'The rest is either:\n\t'+misc.thousandString(self.analysisfolder.results.singeltonBarcodeClusters)+' barcode clusters that are singletons '
        msg += '('+str(misc.percentage(self.analysisfolder.results.singeltonBarcodeClusters,self.analysisfolder.results.barcodeClusterCount)) +'% of barcode_clusters, '
        msg += str(misc.percentage(self.analysisfolder.results.singeltonBarcodeClusters,self.analysisfolder.results.totalReadCount)) +'% or read pairs) and are therefore excluded.\n'
        msg += '\t'+misc.thousandString(len(self.low_read_count_cluster_ids))+' barcode clusters that have less than '+str(self.read_count_cut_off)+' reads '
        msg += '('+str(misc.percentage(len(self.low_read_count_cluster_ids),self.analysisfolder.results.barcodeClusterCount)) +'% of barcode_clusters, '
        msg += str(misc.percentage(sum([tmp[1] for tmp in self.low_read_count_cluster_ids]),self.analysisfolder.results.totalReadCount)) +'% or read pairs) and are therefore excluded.\n'

        return msg

    def run(self):
        
        #self.load_all_barcode_clustes_to_memory()
        self.load_all_barcode_clustes_to_memory_2ndVersion()
        print self.get_initial_stats()
        
        self.add_perfect_barcode_clusters_to_seeds()
        self.add_high_quality_barcode_clusters_to_seeds()
        
        self.build_allele_representation_dict_for_seed_barcode_clusters()
        self.find_unique_allales_among_seed_barcode_clusters()
        
        self.cluster_uniq_alleles()
        self.find_support_for_alleles()
        self.report()
        #self.statistic_graph_report()

    def find_variable_positions(self, cluster_list=None, min_read_count=None):
        """
            Function that returns the number of clusters without sequence information, with non reference base and with a heterozygous variant
            for all reference positions from start of first targeted region to end of last
        """
        
        #
        # imports
        #
        import re
        from seqdata import BarcodeCluster

        msg = 'Searching for variable positions in '
        self.analysisfolder.logfile.write(msg); sys.stdout.write(msg)
        
        #
        # check if the cluster_list is a list of clusters or a list of cluster ids and convert to list of barcode cluster objects
        #
        if cluster_list and (type(cluster_list[0]) == int or (type(cluster_list[0])==str and re.match('^[0-9]+$',cluster_list[0]))):
            tmp_list = []
            for clusterID in cluster_list:
                tmp_list.append( BarcodeCluster(int(clusterID), self.analysisfolder) )
            for cluster in tmp_list: cluster.loadClusterInfo()
            cluster_list = tmp_list
            msg = 'predefined list of '+str(len(cluster_list))+' barcode clusters.\n'
            self.analysisfolder.logfile.write(msg); sys.stdout.write(msg)

        if type(min_read_count) == int or type(min_read_count) == float:
            cluster_list = [barcode_cluster for barcode_cluster in self.barcode_clusters_by_id.values() if barcode_cluster.readPairs >= min_read_count ]
            msg = ''+str(len(cluster_list))+' barcode clusters with at least '+str(min_read_count)+' read pairs.\n'
            self.analysisfolder.logfile.write(msg); sys.stdout.write(msg)

        #
        # build the list of reference positions to include
        #
        tmp_reference_positions = []
        tmp_cluster = cluster_list[0]
        if not tmp_cluster.targetInfo: # if the cluster has not been analyzed before
            tmp_cluster.analyze(createBamIndex=True)
            tmp_cluster.findTargetCoverage()
            tmp_cluster.findHetroZygousBasesInTarget()
            tmp_cluster.updatedb()
        last_exon_end = min([entry['start_position'] for entry in tmp_cluster.targetInfo])-50
        for entry in tmp_cluster.targetInfo:
            for tmp_position in xrange(last_exon_end,entry['end_position']): tmp_reference_positions.append(tmp_position)
            #for tmp_position in xrange(entry['start_position'],entry['end_position']): tmp_reference_positions.append(tmp_position)
            last_exon_end = entry['end_position']

        #
        # create output objects
        #
        output_json = {
            'reference_positions':tmp_reference_positions,
            'non_reference_positions':{ position:0 for position in tmp_reference_positions },
            'missing_data_positions':{ position:0 for position in tmp_reference_positions },
            'hetrozygous_positions':{ position:0 for position in tmp_reference_positions },
            'total_clusters':0
        }

        ####################
        # for backwards compability
        #
        non_reference_positions = { position:0 for position in tmp_reference_positions }
        missing_data_positions  = { position:0 for position in tmp_reference_positions }
        hetrozygous_positions   = { position:0 for position in tmp_reference_positions }
        total_clusters          = 0
        ##################

        #
        # count the number of clusters at each position
        #
        for cluster in cluster_list:

            # if the cluster has not been analyzed before do it now
            if not cluster.targetInfo:
                cluster.analyze(createBamIndex=True)
                cluster.findTargetCoverage()
                cluster.findHetroZygousBasesInTarget()
                cluster.updatedb()

            # count each type of position
            total_clusters += 1# for backwards compability
            output_json['total_clusters'] += 1
            for entry in cluster.targetInfo:
                for position in xrange(entry['start_position'],entry['end_position']):
                    if position in entry['hetrozygous_positions']:
                        hetrozygous_positions[position] += 1# for backwards compability
                        output_json['hetrozygous_positions'][position] += 1
                    if position in entry['non_reference_positions']:
                        non_reference_positions[position] += 1# for backwards compability
                        output_json['non_reference_positions'][position] += 1
                    if position in entry['missing_data']:
                        missing_data_positions[position] += 1# for backwards compability
                        output_json['missing_data_positions'][position] += 1


        ###################
        # for backwards compability
        #
        self.statistic_position_info = []
        self.statistic_position_info.append(tmp_reference_positions)
        self.statistic_position_info.append(hetrozygous_positions)                        
        self.statistic_position_info.append(non_reference_positions)
        self.statistic_position_info.append(missing_data_positions)
        self.statistic_position_info.append(total_clusters)
        ###############

        return output_json

    def add_perfect_barcode_clusters_to_seeds(self, ):
        """ function that finds clusters with high quality alleles in the data """

        import sys
        from seqdata import BarcodeCluster

        msg = 'Loading barcode clusters with no missing data and no heterozygous variants to population of potential seeds ...\n'
        self.analysisfolder.logfile.write(msg); sys.stdout.write(msg)

        # connect to database and extract cluster ids for clusters with high quality data ie no missing information and no heterozygous positions
        self.analysisfolder.database.getConnection()
        #tmp_high_qualitty_cluster_ids = self.analysisfolder.database.c.execute('SELECT clusterId FROM barcodeClusters WHERE hetrozygous_positions<=0 AND high_quality_cluster=1').fetchall()
        tmp_high_qualitty_cluster_ids = self.perfect_barcode_clusters.keys()

        # reformat the list of ids
        #self.high_qualitty_cluster_ids = [int(tmp_info[0]) for tmp_info in tmp_high_qualitty_cluster_ids]
        self.high_qualitty_cluster_ids = tmp_high_qualitty_cluster_ids
        if len(self.high_qualitty_cluster_ids) == 0: sys.stdout.write('WARNING: no highquality clusters found.\n')
        #msg = 'Found '+str(len(self.high_qualitty_cluster_ids))+' barcode clusters, adding to potential seeds ...\n'
        #self.analysisfolder.logfile.write(msg); sys.stderr.write(msg)
        msg = 'Found '+str(len(self.perfect_barcode_clusters))+' barcode clusters, adding to potential seeds ...\n'
        self.analysisfolder.logfile.write(msg); sys.stdout.write(msg)

        #for idnumber in self.high_qualitty_cluster_ids:
        for barcode_cluster in self.perfect_barcode_clusters.values():
            #barcode_cluster = BarcodeCluster(idnumber, self.analysisfolder)
            self.high_qualitty_barcode_clusters.append(barcode_cluster)
            self.potential_seed_clusters.append(barcode_cluster)
            #barcode_cluster.loadClusterInfo()
        
        msg = ''+str(len(self.high_qualitty_cluster_ids))+' barcode clusters, loaded from db and added to potential seeds.\n'
        self.analysisfolder.logfile.write(msg); sys.stdout.write(msg)

    def check_barcode_cluster_for_overlap(self,barcode_cluster):
            if self.analysisfolder.settings.debug: sys.stdout.write( str(cluster.id) +'\n')
            tmp_flag = False
            for entry in barcode_cluster.targetInfo:
                for position, bases in entry['hetrozygous_positions'].iteritems():
                    if self.analysisfolder.settings.debug: sys.stdout.write(  '    position'+str(position)+'\n')
                    if position in self.non_reference_positions_dict:
                        if self.analysisfolder.settings.debug: sys.stdout.write(  'overlaps with non ref position'+'\n')
                        tmp_flag = True
                    else:
                        if self.analysisfolder.settings.debug: sys.stdout.write(  'do not overlap with non ref position! :) check next!'+'\n')
            return tmp_flag

    def add_high_quality_barcode_clusters_to_seeds(self, ):
        
        import misc
        
        msg = '\nAdding barcode clusters with no missing data and heterozygous variants to population of potential seeds ...\n'
        self.analysisfolder.logfile.write(msg); sys.stdout.write(msg)

        clusters_with_hetro_not_missing = [cluster for cluster in self.barcode_clusters_by_id.values() if cluster.high_quality_cluster and cluster.hetrozygous_positions >= 1]

        msg = 'Loading known variable positions ...\n'
        self.analysisfolder.logfile.write(msg); sys.stdout.write(msg)        
        self.variable_position_info = self.find_variable_positions( min_read_count=20 )
        from misc import percentage
        self.non_reference_positions_dict = {}
        for i in range(len(self.variable_position_info['reference_positions'])):
            this_position = self.variable_position_info['reference_positions'][i]
            number_non_reference_clusters_in_this_position = self.variable_position_info['non_reference_positions'][this_position]
            
            number_of_clusters_has_data_in_this_position = self.variable_position_info['total_clusters'] - self.variable_position_info['missing_data_positions'][this_position]
            percenteage_non_ref_clusters_in_this_position = percentage(number_non_reference_clusters_in_this_position,number_of_clusters_has_data_in_this_position)
            
            #if percenteage_non_ref_clusters_in_this_position >= 10:
            if number_non_reference_clusters_in_this_position >= 2:
                self.non_reference_positions_dict[this_position] = percenteage_non_ref_clusters_in_this_position

        msg = 'Checking if the heterozygous variants in '+str(len(clusters_with_hetro_not_missing))+' potential barcode clusters overlap with known variable positions ...\n'
        self.analysisfolder.logfile.write(msg); sys.stdout.write(msg)
        good_counter = 0
        bad_counter = 0
        current_trash = []
        for cluster in clusters_with_hetro_not_missing:

            overlap = self.check_barcode_cluster_for_overlap(cluster)

            if overlap:
                current_trash.append(cluster)
                self.cluster_trash_bin['non clonal']['hetro_bases'][cluster.id] = cluster
                bad_counter += 1
                if self.analysisfolder.settings.debug: sys.stdout.write('    im a junk cluster'+'\n')
            
            elif not overlap:
                self.high_qualitty_barcode_clusters.append(cluster)
                self.potential_seed_clusters.append(cluster)
                good_counter += 1
                if self.analysisfolder.settings.debug: sys.stdout.write('    im a nice and good cluster'+'\n')

        msg = str(good_counter)+' barcodel clusters added to seeds and '+str(bad_counter)+' barcode clusters trashed due to presense of hetrozygous variants overlapping known variants.\n'
        self.analysisfolder.logfile.write(msg); sys.stdout.write(msg)
        sys.stdout.write( str(len(self.cluster_trash_bin['non clonal']['hetro_bases']))+'out of these were'+'classified as non clonal due to presense of hetrozygous bases ('+str(misc.percentage(sum([barcode_cluster.readPairCount for barcode_cluster in self.cluster_trash_bin['non clonal']['hetro_bases'].values()]),self.analysisfolder.results.totalReadCount))+'% of the total read count)\n')

    def build_allele_representation_dict_for_seed_barcode_clusters(self,):
        """ Function find the high quality cluster information"""
        import operator

        msg = '\nBuilding the allele representtions for the population of potential seed barcode clusters ...\n'
        self.analysisfolder.logfile.write(msg); sys.stdout.write(msg)
        
        #find high quality cluster information
        for cluster in self.high_qualitty_barcode_clusters:
            self.build_allele_representation_dict_for_barcode_cluster(cluster)

    def build_allele_representation_dict_for_barcode_cluster(self,cluster,reanalyze=False):
        """ Build the allele representation """
         
        intresting_postitions = {}
        
        if reanalyze:
            cluster.analyze(createBamIndex=True)
            cluster.findTargetCoverage()
            if cluster.targetInfo != []: cluster.findHetroZygousBasesInTarget(include_hetro=True, include_homo_reference=False, include_homo_non_reference=True)
            cluster.removeAllFiles()
        
        cluster.missing_postitions = []
        for entry in cluster.targetInfo:
            
            #if 'no_coverage' in entry and entry ['no_coverage'] == True: print entry['entry_name'],'has no coverage ie is lost'
            #if 'complete_coverage' in entry and entry['complete_coverage']==True: print entry['entry_name'],'is complete has no missing positions'
            
            try: cluster.missing_postitions += entry['missing_data'].keys()
            except KeyError: pass
            
            # check the distribution of bases at the position and which base is most frequent
            for position,information in entry['non_reference_positions'].iteritems():
                
                #### Attention; this part mybe needed some changes which if we had orginal base and insertion, have to be count base and inserted base at the same time!!!!! 
                most_frequent_base = (None,0)
                #print information
                try:
                    for base, count in information['bases'].iteritems(): 
                    # check the highest frequent base in the position
                
                        if count > most_frequent_base[1] and base != 'lowBQ': most_frequent_base = (base, count)
                
                except KeyError:
                    for base, count in information['insertions'].iteritems():
                         if count > most_frequent_base[1] and base != 'InsertlowBQ': most_frequent_base = (base, count)
                intresting_postitions[position] = most_frequent_base[0]
                    
        intresting_postitions[-1] = "START" # dummy position to catch 100% referencce alleles
        # save allele representation as dictionary linked to cluster
        cluster.allele_representation_dict = intresting_postitions
        # print 'positions missing in cluster',cluster.id,'=',cluster.missing_postitions
        pass

    def find_unique_allales_among_seed_barcode_clusters(self,):
        """ Finding unique alleles with high quality clusters"""

        msg = 'Identifying unique allele representtions in the population of potential seed barcode clusters ...\n'
        self.analysisfolder.logfile.write(msg); sys.stdout.write(msg)

        import operator
        
        self.unique_alleles = {}
        
        #    
        # find clusters with identical alllels
        #
        for cluster in self.high_qualitty_barcode_clusters:
            allele_representation_string = '|'.join([str(position)+'='+base for position, base in sorted(cluster.allele_representation_dict.iteritems(), key=operator.itemgetter(0))])
            #print cluster.id, allele_representation_string
            try:
                self.unique_alleles[allele_representation_string].append(cluster)
            except KeyError:
                self.unique_alleles[allele_representation_string] = [cluster]
            
        #
        # sort the identical alleles by count
        #
        self.unique_alleles_by_count = {}
        for allele_representation_string, cluster_list in self.unique_alleles.iteritems(): self.unique_alleles_by_count[allele_representation_string] = len(cluster_list)
        for allele_representation_string, length_of_cluster_id_list in sorted(self.unique_alleles_by_count.iteritems(), key=operator.itemgetter(1), reverse=True):
            cluster_list = self.unique_alleles[allele_representation_string]
            if self.analysisfolder.settings.debug: sys.stdout.write( '\nThe allele is supported by '+str(length_of_cluster_id_list)+' cluster ('+str( cluster_id_list)+')\nallelerepstring="'+str(allele_representation_string)+'"\n')

        #
        # Make a dictionary for allleles
        #
        self.alleles = {}
        tmp_allele_counter = 0
        
        #
        # find all positions where an variation was detected in atleast one barcode_cluster
        #
        self.variable_positions_in_at_least_one_barcode_cluster = {}
        for barcode_cluster in self.high_qualitty_barcode_clusters:
            for position in barcode_cluster.allele_representation_dict.keys():
                self.variable_positions_in_at_least_one_barcode_cluster[position] = True

        #
        # print table for manual check during development
        #
        if self.analysisfolder.settings.debug: print '######### unique alleles'
        if self.analysisfolder.settings.debug: print 'id\pos\t'+'\t'.join([str(position) for position in self.variable_positions_in_at_least_one_barcode_cluster])+'\tIDs' # prints the header
        
        #for barcode_cluster in self.high_qualitty_barcode_clusters:
        barcode_clusters_to_compare = []
        self.alleles_sorted_by_barcode_cluster_count = []
        for allele_representation_string, length_of_barcode_cluster_id_list in sorted(self.unique_alleles_by_count.iteritems(), key=operator.itemgetter(1), reverse=True):
            
            # counter to create a unique allele id
            tmp_allele_counter += 1
            
            # get the list of  barcode_clusters with identical alleles
            barcode_cluster_list = self.unique_alleles[allele_representation_string]
            
            # get a representative barcode_cluster to compare always choose first one in the list, could later be changed to the one with highest read count
            barcode_cluster = barcode_cluster_list[0]
            barcode_clusters_to_compare.append(barcode_cluster) # to know barcode_cluster to compare later maybe not needed anymore?
            
            #dictionary for candidate allele
            this_allele = {
                        'id':tmp_allele_counter,
                        'seeding_barcode_cluster':barcode_cluster_list[0], # representative for original uniuqe allele
                        # 'barcode_clusters_by_difference':{0:barcode_cluster_list}, # all barcode_clusters soreted by difference to the seed
                        'total_barcode_cluster_count':len(barcode_cluster_list), # total number of barcode_clusters supporting this allele
                        'barcode_clusters':barcode_cluster_list, # list of all barcode_clusters supporting this allele
                        'this_allele_clustered_to':None,
                        'added_to_allele_cluster_at_iteration':None,
                        'recruited_by':None,
                        'missmatches_to_seed':0,
                        'has_recruited':[]
                    }
            
            # save this allele to a dictionary and a list
            self.alleles[tmp_allele_counter] = this_allele
            self.alleles_sorted_by_barcode_cluster_count.append(self.alleles[tmp_allele_counter])
            
            # print some info START
            #print ','.join([str(tmp_barcode_cluster.id) for tmp_barcode_cluster in barcode_cluster_list])+'\t',
            #print this_allele['id'],str(len(barcode_cluster_list))+'\t',
            if self.analysisfolder.settings.debug:
                print str(this_allele['id'])+'\t',
            
                #print the positions for alleles
                for position in self.variable_positions_in_at_least_one_barcode_cluster:
                    try:
                        print barcode_cluster.allele_representation_dict[position],'\t',
                    except KeyError:
                        print '*','\t',
                print ','.join([str(tmp_barcode_cluster.id) for tmp_barcode_cluster in sorted(barcode_cluster_list)])#+'\t'
                # print some END

        if self.analysisfolder.settings.debug: 
            print ''
            print '######### unique alleles end'

    def print_allele_cluster_details(self, allele_cluster):
        sys.stdout.write( '# Allele cluster '+str(allele_cluster['id'])+':\n')
        sys.stdout.write( '\t\t'+'\t'.join([str(position) for position in sorted(self.variable_positions_in_at_least_one_barcode_cluster)])+'\tIDs\n') # prints the header
        
        for this_allele in allele_cluster['alles_in_this_cluster'].values():
            sys.stdout.write( 'it='+str(this_allele['added_to_allele_cluster_at_iteration'])+'\tid='+str(this_allele['id'])+'\t')
            for position in sorted(self.variable_positions_in_at_least_one_barcode_cluster):
                try:
                    if position in allele_cluster['seed_for_this_allele_cluster']['seeding_barcode_cluster'].allele_representation_dict and this_allele['seeding_barcode_cluster'].allele_representation_dict[position] == allele_cluster['seed_for_this_allele_cluster']['seeding_barcode_cluster'].allele_representation_dict[position]:
                        sys.stdout.write( str(this_allele['seeding_barcode_cluster'].allele_representation_dict[position])+'\t')
                    else:
                        RED = "\033[1;91m"
                        COLOR_STOP = "\033[0m"
                        sys.stdout.write( RED+this_allele['seeding_barcode_cluster'].allele_representation_dict[position]+COLOR_STOP+'\t')
                except KeyError:
                    sys.stdout.write( '*'+'\t')
            sys.stdout.write( ','.join([str(tmp_barcode_cluster.id) for tmp_barcode_cluster in this_allele['barcode_clusters']])+'\t\n')
        
        sys.stdout.write( str(len(sorted([cluster.id for cluster in set(sorted(allele_cluster['barcode_clusters_in_this_allele_cluster']+allele_cluster['supporting_barcode_clusters']))])))+' barcode clusters, fist 100 => ')
        sys.stdout.write( str(sorted([cluster.id for cluster in set(sorted(allele_cluster['barcode_clusters_in_this_allele_cluster']+allele_cluster['supporting_barcode_clusters']))][0:100]))+'\n')#+'\t'+str([cluster.id for cluster in allele_cluster['supporting_barcode_clusters']])+'\t'
        
        my_id_list = [cluster for cluster in allele_cluster['barcode_clusters_in_this_allele_cluster']]+[cluster for cluster in allele_cluster['supporting_barcode_clusters']]
        self.find_individuals_id_in_clusters( my_id_list )
        sys.stdout.write( '\n')

    def cluster_uniq_alleles(self, number_of_errors_allowed = 1):
        """ This functions makes Seed alleles as dictionary and clustering them with some analysis for each cluster, also at the end of this function base on the seed allels for some clusters which have diferences in only one positions, making of clusters called Recruiters for supporting of Seed allels would be done"""

        msg = '\nClustering the unique the alleles that was found in the population of potential seed barcode clusters ...\n'
        self.analysisfolder.logfile.write(msg); sys.stdout.write(msg)
        
        import operator
        
        #
        #Dictionary for clustering alleles
        #
        self.allele_clusters = {}
        
        tmp_allele_cluster_counter = 0
        import itertools
        
        # finding seed alleles and print them
        for seed_allele in self.alleles_sorted_by_barcode_cluster_count:
            
            if self.analysisfolder.settings.debug: print '\nlooking at potential seed with id=',seed_allele['id']
            
            #print the seed allels and already clustred alleles
            if seed_allele['this_allele_clustered_to'] != None:
                if self.analysisfolder.settings.debug: print 'seed',seed_allele['id'],'is already clustered to',seed_allele['this_allele_clustered_to'],'continuing with next seed'
                continue
            else:
                tmp_allele_cluster_counter += 1                
                
                if self.analysisfolder.settings.debug: print '# creating allelecluster',tmp_allele_cluster_counter,'around allele',seed_allele['id'],'as seed'
                
                #
                # dictionary for alleles which can be clustered with seed alllels 
                #
                allele_cluster = {
                    'id':tmp_allele_cluster_counter,
                    'seed_for_this_allele_cluster':seed_allele,
                    'alles_in_this_cluster':{seed_allele['id']:seed_allele}, # new barcode_clusters added since last iteration of "allele barcode_clustering"
                    'new_clusters_since_last_iteration':[seed_allele],
                    'iteration':0,
                    'barcode_clusters_in_this_allele_cluster':[barcode_cluster for barcode_cluster in seed_allele['barcode_clusters']],
                    'network':{},
                    'supporting_barcode_clusters':[]
                }
                seed_allele['this_allele_clustered_to'] = tmp_allele_cluster_counter
                seed_allele['added_to_allele_cluster_at_iteration'] = 0
                
                while allele_cluster['new_clusters_since_last_iteration']:
                    
                    allele_cluster['iteration'] += 1
                    recruiters = allele_cluster['new_clusters_since_last_iteration']
                    allele_cluster['new_clusters_since_last_iteration'] = []
                    if self.analysisfolder.settings.debug: print '|------Starting iteration',allele_cluster['iteration'],'for allele cluster',allele_cluster['id'],'using alleles',','.join([str(recruiter['id']) for recruiter in recruiters]),'as recruiters'
                    if allele_cluster['iteration'] >= 5: sys.stderr.write( 'WARNING!!!! now starting iteration '+str(allele_cluster['iteration'])+' for cluster '+str(allele_cluster['id'])+'\n')
                    
                    for recruiter_allele in recruiters:
                        if self.analysisfolder.settings.debug: print '|  |---current recruiter',recruiter_allele['id'],' comparing to all potential candidates'
                                                
                        for candidate_allele in self.alleles_sorted_by_barcode_cluster_count:
                            if self.analysisfolder.settings.debug: print '|  |   |---comparing recruiter',recruiter_allele['id'],'to candidate with id',candidate_allele['id']
                            
                            if recruiter_allele == candidate_allele:
                                if self.analysisfolder.settings.debug:print '|  |   |   \---recruiter and candidate are same (',recruiter_allele['id'],'==',candidate_allele['id'],'), allele cannot recruit itself to cluster, continuing with next candidate'
                                continue
                            
                            if candidate_allele['this_allele_clustered_to'] != None:
                                if self.analysisfolder.settings.debug:print '|  |   |   \---candidate',candidate_allele['id'],'is already clustered to',candidate_allele['this_allele_clustered_to'],', a candidate cannot be recruited twice, continuing with next candidate'
                                continue
                            
                            number_variable_positions, difference_to_seed, missing_position_count, same_variant_count,both_reference_count = self.compare_allele_representation( recruiter_allele['seeding_barcode_cluster'], candidate_allele['seeding_barcode_cluster'] )
                            
                            if difference_to_seed <= 1 : # make to a setting!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
                                if self.analysisfolder.settings.debug:print '|  |   |   \---recruiter',recruiter_allele['id'],'and candidate',candidate_allele['id'],'have',difference_to_seed,'differences between them we therefore add',candidate_allele['id'],'to allele cluster',allele_cluster['id']
                                
                                allele_cluster['alles_in_this_cluster'][candidate_allele['id']] = candidate_allele
                                allele_cluster['new_clusters_since_last_iteration'].append(candidate_allele)
                                allele_cluster['barcode_clusters_in_this_allele_cluster'] += candidate_allele['barcode_clusters']
                                allele_cluster['network']

                                candidate_allele['added_to_allele_cluster_at_iteration'] = allele_cluster['iteration']
                                candidate_allele['this_allele_clustered_to'] = allele_cluster['id']
                                candidate_allele['recruited_by'] = recruiter_allele['id']
                                candidate_allele['missmatches_to_seed'] = self.compare_allele_representation(seed_allele['seeding_barcode_cluster'], candidate_allele['seeding_barcode_cluster'])
                                recruiter_allele['has_recruited'].append( candidate_allele )
                            else:
                                if self.analysisfolder.settings.debug:print '|  |   |   \---recruiter',recruiter_allele['id'],'and candidate',candidate_allele['id'],'have',difference_to_seed,'differences between more than our cutoff'
                                continue
                        if self.analysisfolder.settings.debug:print'|  |   \--- Recruiter',recruiter_allele['id'],' complete'
                            
                    if self.analysisfolder.settings.debug:print '|  \iteration complete!'
                    if self.analysisfolder.settings.debug:print'|'
                if self.analysisfolder.settings.debug:print'\-cluster complete after',allele_cluster['iteration'],'iterations'
                
            self.allele_clusters[allele_cluster['id']] = allele_cluster

        #print ''
        sys.stdout.write( '######### allele clusters found:\n')
        for allele_cluster in self.allele_clusters.values():
            self.print_allele_cluster_details(allele_cluster)
        sys.stdout.write( '######### allele clustering done\n\n')

    def compare_allele_representation(self,cluster1,cluster2,dont_count_missing=True):

        ''' NOW comparing only known variable positions in the highQ clusters, maybe include the private varaianles between the two clusters aswell these could be PCR errors
            in that case we would need to add some variable tracking those like the variable_positions_in_at_least_one_cluster dict above but not overlapping with the self.variable_positions_in_at_least_one_barcode_cluster dict
            variable_positions_in_at_least_one_cluster = self.variable_positions_in_at_least_one_barcode_cluster.'''
        
        import misc

        variable_positions_in_at_least_one_cluster = {}
        for cluster in [cluster1,cluster2]:
             for position in cluster.allele_representation_dict.keys(): variable_positions_in_at_least_one_cluster[position] = True
        
        for position in self.variable_positions_in_at_least_one_barcode_cluster: variable_positions_in_at_least_one_cluster[position] = True

        #
        # print table for manual check during development
        #
        #print '\t'+'\t'.join([str(position) for position in variable_positions_in_at_least_one_cluster])
        #clusters_to_compare = []
        # for allele_representation_string, length_of_cluster_id_list in sorted(self.unique_alleles_by_count.iteritems(), key=operator.itemgetter(1), reverse=True):
        #for cluster in [cluster1,cluster2]:
            #cluster_list = self.unique_alleles[allele_representation_string]
            #cluster = cluster_list[0]
            #clusters_to_compare.append(cluster)
            #print ','.join([str(tmp_cluster.id) for tmp_cluster in cluster_list])+'\t',
            #print str(cluster.id)+'\t',
            #for position in variable_positions_in_at_least_one_cluster:
                #try:
                    #print cluster.allele_representation_dict[position],'\t',
                #except KeyError:
                    #print '*','\t',
            #print ''
        #print len(variable_positions_in_at_least_one_cluster)
        
        non_equal_position_count = 0
        missing_position_count = 0
        same_variant_count = 0
        both_reference_count=0
        for position in variable_positions_in_at_least_one_cluster:
            try:
                if cluster1.allele_representation_dict[position] != cluster2.allele_representation_dict[position]:
                    # both are non reference but they differ
                    non_equal_position_count += 1
                elif cluster1.allele_representation_dict[position] == cluster2.allele_representation_dict[position]:
                    # both are non reference but same base do nothing
                    same_variant_count +=1
                else:
                    print 'funky'
            except KeyError:
                # one base is reference the other not
                if dont_count_missing:
                    if position in cluster1.missing_postitions or position in cluster2.missing_postitions:
                        missing_position_count+=1
                    elif position not in cluster1.allele_representation_dict and position not in cluster2.allele_representation_dict:
                        both_reference_count +=1
                    else:
                        non_equal_position_count += 1
                else: non_equal_position_count += 1
        assert len(variable_positions_in_at_least_one_cluster) == sum([non_equal_position_count,missing_position_count,same_variant_count,both_reference_count])
        #print 'comparing cluster=',cluster1.id,'vs cluster=',cluster2.id,'out of',len(variable_positions_in_at_least_one_cluster),'non reference positions in any of the clusters there are:','differences=',non_equal_position_count,'missingdata=',missing_position_count,'same_non_ref_base=',same_variant_count
        #print 'comparing cluster=',cluster1.id,'vs cluster=',cluster2.id,'out of',len(variable_positions_in_at_least_one_cluster),'non ref. pos. in any of the clusters there are:','differences=',misc.percentage(non_equal_position_count,len(variable_positions_in_at_least_one_cluster)),'missingdata=',misc.percentage(missing_position_count,len(variable_positions_in_at_least_one_cluster)),'same_base=',misc.percentage(same_variant_count+both_reference_count,len(variable_positions_in_at_least_one_cluster))

        
        percentage_difference = misc.percentage(non_equal_position_count,len(variable_positions_in_at_least_one_cluster))
        #print percentage_difference,'% difference between the variable positions in the allele representation of the two clusters '+str(cluster1.id)+' and '+str(cluster2.id)+' (',non_equal_position_count,'out of',len(variable_positions_in_at_least_one_cluster),' variable positions are different).'
        
        return len(variable_positions_in_at_least_one_cluster), non_equal_position_count, missing_position_count, same_variant_count,both_reference_count

    def find_support_for_alleles(self,):
        """ Now with this function we try to finding the clusters which have similarity with defined main alleles for covering the clusters with shortage of information in regions """ 
        import misc

        msg = '\nmaking post clustering summary:\n'
        self.analysisfolder.logfile.write(msg); sys.stdout.write(msg)

        self.analysisfolder.database.getConnection()
        tmp_read_counts = sum([barcode_cluster.readPairCount for barcode_cluster in self.barcode_clusters_by_id.values()])+self.analysisfolder.results.singeltonBarcodeClusters

        high_quality_clusters = [barcode_cluster  for barcode_cluster in self.barcode_clusters_by_id.values() if barcode_cluster.hetrozygous_positions==0 and barcode_cluster.high_quality_cluster]
        tmp_read_counts = [barcode_cluster.readPairCount  for barcode_cluster in high_quality_clusters]
        tmp_read_counts = sum(tmp_read_counts)#sum([i[0] for i in tmp_read_counts])
        sys.stdout.write( str(len(high_quality_clusters))+' clusters have no missing data and are not hetrozygous '+str(misc.percentage(tmp_read_counts,self.analysisfolder.results.totalReadCount))+'% of total reads\n')
        clusters_with_hetro_not_missing = [barcode_cluster  for barcode_cluster in self.barcode_clusters_by_id.values() if barcode_cluster.hetrozygous_positions>=1 and barcode_cluster.high_quality_cluster]
        tmp_read_counts = [barcode_cluster.readPairCount  for barcode_cluster in clusters_with_hetro_not_missing]
        tmp_read_counts = sum(tmp_read_counts)#sum([i[0] for i in tmp_read_counts])
        sys.stdout.write( str(len(clusters_with_hetro_not_missing))+' clusters have no missing data but are hetrozygous '+str(misc.percentage(tmp_read_counts,self.analysisfolder.results.totalReadCount))+'% of total reads\n')
        
        tmp_sum = 0
        for allele_cluster in self.allele_clusters.values():
            allele_cluster_sum = 0
            for barcode_cluster in allele_cluster['barcode_clusters_in_this_allele_cluster']:
                tmp_sum += barcode_cluster.readPairCount
                allele_cluster_sum += barcode_cluster.readPairCount
            sys.stdout.write( 'Allele cluster '+str(allele_cluster['id'])+' has '+str(misc.percentage(allele_cluster_sum,self.analysisfolder.results.totalReadCount))+'% of the total read count\n')
        sys.stdout.write( 'A total of '+str(misc.percentage(tmp_sum,self.analysisfolder.results.totalReadCount))+'% of the reads are in the alleles ('+misc.thousandString(tmp_sum)+' out of '+misc.thousandString(self.analysisfolder.results.totalReadCount)+')\n')

        msg = '\nLooking for support for the alleles clusters among barcode_clusters with missing data ...\n'
        self.analysisfolder.logfile.write(msg); sys.stdout.write(msg)
        clusters_not_hetro_with_missing = [barcode_cluster  for barcode_cluster in self.barcode_clusters_by_id.values() if barcode_cluster.hetrozygous_positions==0 and not barcode_cluster.high_quality_cluster]
        tmp_read_counts = [barcode_cluster.readPairCount  for barcode_cluster in clusters_not_hetro_with_missing]
        tmp_read_counts = sum(tmp_read_counts)#sum([i[0] for i in tmp_read_counts])
        sys.stdout.write( str(len(clusters_not_hetro_with_missing))+' clusters with missing data and no hetrozygous '+str(misc.percentage(tmp_read_counts,self.analysisfolder.results.totalReadCount))+'% of total reads\n')
        clusters_with_hetro_with_missing = [barcode_cluster  for barcode_cluster in self.barcode_clusters_by_id.values() if barcode_cluster.hetrozygous_positions>=1 and not barcode_cluster.high_quality_cluster]
        tmp_read_counts = [barcode_cluster.readPairCount  for barcode_cluster in clusters_with_hetro_with_missing]
        tmp_read_counts = sum(tmp_read_counts)#sum([i[0] for i in tmp_read_counts])
        sys.stdout.write( str(len(clusters_with_hetro_with_missing))+' clusters with missing data and are hetrozygous '+str(misc.percentage(tmp_read_counts,self.analysisfolder.results.totalReadCount))+'% of total reads\n')

        msg = 'Trying to add these '+str(len(clusters_with_hetro_with_missing+clusters_not_hetro_with_missing))+' barcode_clusters with missing data to the allele clusters.\n'
        self.analysisfolder.logfile.write(msg); sys.stdout.write(msg)

        good_counter = 0
        bad_counter = 0
        current_trash = {
            'non clonal':{
                'individual_id':{},
                'hetro_bases':{}
            },
            'Low_read_count':{},
            'No_similarity_to_allele_cluster':{},
            'matching_more_than_1_allele_cluster':{},
        }
        #p = misc.Progress(len(clusters_not_hetro_with_missing),unit='clusters')
        cluster_junk = []
        
        sys.stdout.write( "comparing barcode with missing data clusters to allele_clusters\n" )
        for barcode_cluster in clusters_with_hetro_with_missing+clusters_not_hetro_with_missing:

            if self.analysisfolder.settings.debug: print 'cluster',barcode_cluster.id,'has',barcode_cluster.readPairCount,'read pairs'

            overlap = self.check_barcode_cluster_for_overlap(barcode_cluster)
            if overlap:
                self.cluster_trash_bin['non clonal']['hetro_bases'][barcode_cluster.id] = barcode_cluster
                current_trash['non clonal']['hetro_bases'][barcode_cluster.id] = barcode_cluster
                cluster_junk.append(barcode_cluster)
                bad_counter += 1
                if self.analysisfolder.settings.debug:print 'the cluster is non clonal overlaps hetro bases'
                continue
            elif not overlap:
                good_counter += 1
                if self.analysisfolder.settings.debug:print 'no hetrozygous variant overlap found to known variable positions'
            else:print'Error!!';sys.exit()

            if barcode_cluster.readPairCount < 10:
                if self.analysisfolder.settings.debug: print 'cluster',barcode_cluster.id,'has to few reads'
                cluster_junk.append(barcode_cluster)
                self.cluster_trash_bin['Low_read_count'][barcode_cluster.id] = barcode_cluster
                current_trash['Low_read_count'][barcode_cluster.id] = barcode_cluster
                #p.update()
                continue
            self.build_allele_representation_dict_for_barcode_cluster(barcode_cluster,reanalyze=False)
            matchin_count = 0
            matchin_id=None
            for allele_cluster in self.allele_clusters.values():
                cluster1=barcode_cluster
                cluster2=allele_cluster['seed_for_this_allele_cluster']['seeding_barcode_cluster']
                if self.analysisfolder.settings.debug: print '    allelecluster=',allele_cluster['id'],'clusterrep.=',cluster2.id,
                variable_positions_count, non_equal_position_count, missing_position_count, same_variant_count, both_reference_count = self.compare_allele_representation(cluster1,cluster2,dont_count_missing=True)
                if self.analysisfolder.settings.debug: print 'comparing cluster=',cluster1.id,'vs cluster=',cluster2.id,'out of',variable_positions_count,'non ref. pos. in any of the clusters there are:','differences=',misc.percentage(non_equal_position_count,variable_positions_count),'missingdata=',misc.percentage(missing_position_count,variable_positions_count),'same_base=',misc.percentage(same_variant_count+both_reference_count,variable_positions_count)
                if non_equal_position_count == 0 and (missing_position_count!=variable_positions_count):
                    matchin_count+=1
                    matchin_id=allele_cluster['id']
                    if self.analysisfolder.settings.debug: print 'comparing cluster=',cluster1.id,'vs cluster=',cluster2.id,'out of',variable_positions_count,'non ref. pos. in any of the clusters there are:','differences=',misc.percentage(non_equal_position_count,variable_positions_count),'missingdata=',misc.percentage(missing_position_count,variable_positions_count),'same_non_ref_base=',misc.percentage(same_variant_count+both_reference_count,variable_positions_count)
                else:
                    if self.analysisfolder.settings.debug: print 'nomatch'
            if matchin_count == 1:
                if self.analysisfolder.settings.debug: print 'THIS IS allele_cluster',matchin_id
                self.allele_clusters[matchin_id]['supporting_barcode_clusters'].append(barcode_cluster)
            elif matchin_count == 0:
                cluster_junk.append(barcode_cluster)
                self.cluster_trash_bin['No_similarity_to_allele_cluster'][barcode_cluster.id] = barcode_cluster
                current_trash['No_similarity_to_allele_cluster'][barcode_cluster.id] = barcode_cluster
            else:
                cluster_junk.append(barcode_cluster)
                self.cluster_trash_bin['matching_more_than_1_allele_cluster'][barcode_cluster.id] = barcode_cluster
                current_trash['matching_more_than_1_allele_cluster'][barcode_cluster.id] = barcode_cluster
            #p.update()
        junk_sum = sum([barcode_cluster.readPairCount for barcode_cluster in cluster_junk])
        sys.stdout.write( str(len(cluster_junk))+' out of '+str(len(clusters_with_hetro_with_missing+clusters_not_hetro_with_missing))+' could not be placed ('+str(misc.percentage(len(cluster_junk),len(clusters_with_hetro_with_missing+clusters_not_hetro_with_missing)))+'%) '+str(junk_sum)+' reads ie '+str(misc.percentage(junk_sum,self.analysisfolder.results.totalReadCount))+'% of the total read count\n')
        sys.stdout.write( str(len(current_trash['matching_more_than_1_allele_cluster']))+' out of these were '+'matching more than one allele_cluster ('+str(misc.percentage(sum([barcode_cluster.readPairCount for barcode_cluster in current_trash['matching_more_than_1_allele_cluster'].values()]),self.analysisfolder.results.totalReadCount))+'% of the total read count)\n')
        sys.stdout.write( str(len(current_trash['No_similarity_to_allele_cluster']))+     ' out of these had '+'to little similarity to any allele cluster ('+                    str(misc.percentage(sum([barcode_cluster.readPairCount for barcode_cluster in current_trash['No_similarity_to_allele_cluster'].values()]),self.analysisfolder.results.totalReadCount))+'% of the total read count)\n')
        sys.stdout.write( str(len(current_trash['non clonal']['hetro_bases']))+           'out of these were '+'classified as non clonal due to presense of hetrozygous bases ('+str(misc.percentage(sum([barcode_cluster.readPairCount for barcode_cluster in current_trash['non clonal']['hetro_bases'].values()]),self.analysisfolder.results.totalReadCount))+'% of the total read count)\n')
        sys.stdout.write( str(len(current_trash['Low_read_count']))+                      'out of these were '+'Low_read_count barcode clusters ('+                              str(misc.percentage(sum([barcode_cluster.readPairCount for barcode_cluster in current_trash['Low_read_count'].values()]),self.analysisfolder.results.totalReadCount))+'% of the total read count)\n')
 
        sys.stdout.write( '\n')
        sys.stdout.write( '# NOW:\n')
        tmp_sum = 0
        for allele_cluster in self.allele_clusters.values():
            allele_cluster_sum = 0
            for barcode_cluster in allele_cluster['barcode_clusters_in_this_allele_cluster']+allele_cluster['supporting_barcode_clusters']:
                tmp_sum += barcode_cluster.readPairCount
                allele_cluster_sum += barcode_cluster.readPairCount
            sys.stdout.write( 'allele cluster ='+str(allele_cluster['id'])+' has '+str(misc.percentage(allele_cluster_sum,self.analysisfolder.results.totalReadCount))+'% of the total read count\n')
        
        sys.stdout.write( str(tmp_sum)+ ' reads '+str(misc.percentage(tmp_sum,self.analysisfolder.results.totalReadCount))+'% of total are in the alleles ('+misc.thousandString(tmp_sum)+' out of '+misc.thousandString(self.analysisfolder.results.totalReadCount)+')\n')
        sys.stdout.write( '\n')

    def find_individuals_id_in_clusters(self, list_of_clusters):
        """ Functions find the individual's information and reports which individuals have which alleles""" 
        
        from seqdata import BarcodeCluster        
        from collections import Counter
        from misc import percentage
        import operator
        
        tmp_dictionary = {}
       
        for barcode_cluster in list_of_clusters:
            
            if type(barcode_cluster)== int:
                barcode_cluster = BarcodeCluster (barcode_cluster, self.analysisfolder)
                barcode_cluster.loadClusterInfo()
            
            try: tmp_dictionary[ barcode_cluster.individual_id ] += 1
            except KeyError: tmp_dictionary[ barcode_cluster.individual_id ] = 1

        sys.stdout.write( 'Individual id information in barcode clusters:'+'\n')
        sys.stdout.write( 'clusters\tid'+'\n')
        for id_number, count in sorted(tmp_dictionary.iteritems(), key=operator.itemgetter(1),reverse=True):
            sys.stdout.write( str(count)+'\t'+str(id_number) +'\n')
    
    def statistic_graph_report(self, genomic_position=True):
        """ Function reports the statistical result for position variation with graph visualization """
        
        import sys
        #import numpy as np
        #import pylab as P
        import matplotlib.pyplot as plt
        import misc
        #from matplotlib import rc
        #rc('mathtext', default='regular')

        tmp_position_list = self.statistic_position_info[0]
        hetrozygous_positions = self.statistic_position_info[1]
        non_reference_positions = self.statistic_position_info[2]
        missing_data_positions = self.statistic_position_info[3]
        total_clusters = self.statistic_position_info[4]
        # exon_position_list_for_hatch = self.statistic_position_info[5]
        
        if genomic_position != False:
            fig = plt.figure()
            ax1 = fig.add_subplot(111)
            y = []
            for tmp_pos in tmp_position_list:
                if missing_data_positions[tmp_pos] != 0: y.append( 100-(misc.percentage(missing_data_positions[tmp_pos],total_clusters)) )
                else: y.append( 0 )
            
            # y_for_exon_hatch = []
            # for tmp_pos_hatch in exon_position_list_for_hatch:
            #     if missing_data_positions[tmp_pos_hatch] != 0: y_for_exon_hatch.append( 100-(misc.percentage(missing_data_positions[tmp_pos_hatch],total_clusters)) )
            #     else: y_for_exon_hatch.append( 0 )
            
            ax1.plot(tmp_position_list, y, '-', label = 'coverage',color="green")
            ax1.fill_between(tmp_position_list,y, color="green", alpha=0.5)
            
            # ax1.fill_between(exon_position_list_for_hatch, y_for_exon_hatch, color="none", hatch="//", edgecolor="b", linewidth=0.0)
            
            ax1.plot( tmp_position_list, [misc.percentage(non_reference_positions[tmp_pos],total_clusters) for tmp_pos in tmp_position_list], '-', label = 'non-ref')
            twoaxis = False
            if twoaxis:
                ax2 = ax1.twinx()
                ax2.plot( tmp_position_list, [misc.percentage(hetrozygous_positions[tmp_pos],total_clusters) for tmp_pos in tmp_position_list], '-r', label = 'hetro')
            else:
                ax1.plot( tmp_position_list, [misc.percentage(hetrozygous_positions[tmp_pos],total_clusters) for tmp_pos in tmp_position_list], '-r', label = 'hetro')
        else:
            fig = plt.figure()
            ax1 = fig.add_subplot(111)
            y = []
            for tmp_pos in tmp_position_list:
                if missing_data_positions[tmp_pos] != 0: y.append( 100-(misc.percentage(missing_data_positions[tmp_pos],total_clusters)) )
                else: y.append( 0 )
            ax1.plot(range(len(tmp_position_list)), y, '-', label = 'coverage',color="green")
            ax1.fill_between(range(len(tmp_position_list)),y, color="green",alpha=0.5)
            #ax1.fill_between(range(80,150),y, color="none", hatch="//", edgecolor="b", linewidth=0.0)
            
            ax1.plot( range(len(tmp_position_list)), [misc.percentage(non_reference_positions[tmp_pos],total_clusters) for tmp_pos in tmp_position_list], '-', label = 'non-ref')
            twoaxis = False
            if twoaxis:
                ax2 = ax1.twinx()
                ax2.plot( range(len(tmp_position_list)), [misc.percentage(hetrozygous_positions[tmp_pos],total_clusters) for tmp_pos in tmp_position_list], '-r', label = 'hetro')
            else:
                ax1.plot(range(len(tmp_position_list)), [misc.percentage(hetrozygous_positions[tmp_pos],total_clusters) for tmp_pos in tmp_position_list], '-r', label = 'hetro')
        
    
        ax1.legend(loc='center left', bbox_to_anchor=(1, 0.5))
        ax1.grid()
        ax1.set_xlabel('HLA-A Sequence Position')
        ax1.set_ylabel('Percentage')
        if twoaxis:
            ax2.set_ylabel('Percentage')
            ax2.legend(loc='center left', bbox_to_anchor=(1, 0.5))
            ax2.set_ylim(0,15)
        ax1.set_ylim(0, 100)
        plt.show()
        
        
        ##### As a alternative for other type of plot graph
        # if genomic_position:
        #     y = []
        #     for tmp_pos in tmp_position_list:
        #         if missing_data_positions[tmp_pos] != 0: y.append( 100-(misc.percentage(missing_data_positions[tmp_pos],total_clusters)) )
        #         else: y.append( 0 )
        #         
        #     plt.stackplot( tmp_position_list, y, colors=['green','green'],alpha=0.2)
        #     
        #     plt.stackplot( tmp_position_list, [misc.percentage(non_reference_positions[tmp_pos],total_clusters)
        #                                        for tmp_pos in tmp_position_list], colors=['blue','blue'],alpha=0.8)
        #     
        #     plt.stackplot( tmp_position_list, [misc.percentage(hetrozygous_positions[tmp_pos],total_clusters)
        #                                        for tmp_pos in tmp_position_list], colors=['red','red'],alpha=0.6)
        # else:
        #     plt.stackplot( range(len(tmp_position_list)), [100-(misc.percentage(missing_data_positions[tmp_pos],total_clusters))
        #                                                    for tmp_pos in tmp_position_list], colors=['green','green'],alpha=0.2)
        #     
        #     plt.stackplot( range(len(tmp_position_list)), [misc.percentage(non_reference_positions[tmp_pos],total_clusters)
        #                                                    for tmp_pos in tmp_position_list], colors=['blue','blue'],alpha=0.8)
        #     
        #     plt.stackplot( range(len(tmp_position_list)), [misc.percentage(hetrozygous_positions[tmp_pos],total_clusters)
        #                                                    for tmp_pos in tmp_position_list], colors=['red','red'],alpha=0.6)
        # 
        # plt.xlabel('HLA-A Sequence Position')
        # plt.ylabel('Percentage')
        # plt.ylabel('Percentage')
        # plt.title('Individual position Info')
        # plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))
        # plt.show()
        
        return 0

    def report(self, ):
        """ Report the machine resultes in the terminal for primary information"""
        
        #
        # import
        #
        import misc
        import operator
        
        tmp_read_count = sum([barcode_cluster.readPairCount for barcode_cluster in self.cluster_trash_bin['non clonal']['hetro_bases'].values()])
        msg = 'In total '+str(len(self.cluster_trash_bin['non clonal']['hetro_bases']))+' barcode_clusters have been trashed as they overlap variable positions with hetrozygous variant(s) ('+str(misc.percentage(tmp_read_count,self.analysisfolder.results.totalReadCount))+')% of total reads.\n'
        self.analysisfolder.logfile.write(msg); sys.stdout.write(msg)
        
        sys.stdout.write( '\n')
        sys.stdout.write( '######### allele clusters:\n\n')
        
        for allele_cluster in self.allele_clusters.values():
            self.print_allele_cluster_details(allele_cluster)

        sys.stdout.write( '######### by individual:\n\n')

        ind_ids = {}
        for barcode_cluster in self.barcode_clusters_by_id.values():
            barcode_cluster.in_allele = None
            try:             ind_ids[ barcode_cluster.individual_id ].append(barcode_cluster)
            except KeyError: ind_ids[ barcode_cluster.individual_id ]    =  [barcode_cluster]

        for allele_cluster in self.allele_clusters.values():
            for barcode_cluster in allele_cluster['barcode_clusters_in_this_allele_cluster']+allele_cluster['supporting_barcode_clusters']:
                barcode_cluster.in_allele = 'allele '+str(allele_cluster['id'])
                if False: barcode_cluster.analyze(createBamIndex=True)
        for barcode_cluster in self.cluster_trash_bin['matching_more_than_1_allele_cluster'].values(): barcode_cluster.in_allele = 'trashed (match many)'
        for barcode_cluster in self.cluster_trash_bin['No_similarity_to_allele_cluster'].values():barcode_cluster.in_allele = 'trashed (match none)'
        for barcode_cluster in self.cluster_trash_bin['non clonal']['hetro_bases'].values():barcode_cluster.in_allele = 'trashed (hetro bases)'
        for barcode_cluster in self.cluster_trash_bin['Low_read_count'].values():barcode_cluster.in_allele = 'trashed (low read count)'

        sys.stdout.write( 'LEGEND:\n')
        sys.stdout.write( 'trc = total read count\n')
        sys.stdout.write( 'bc = barcode cluster\n')
        sys.stdout.write( 'bci = barcodes cluster in individual\n')
        sys.stdout.write( 'rci = read counts in individual\n')
        sys.stdout.write( '\n')
        
        for ind_id, barcode_clusters, tmp_junk in sorted([(ind_id, barcode_clusters,sum([barcode_cluster.readPairCount for barcode_cluster in barcode_clusters])) for ind_id, barcode_clusters in ind_ids.iteritems()], key=operator.itemgetter(2), reverse=True):
        #for ind_id, barcode_clusters in ind_ids.iteritems():
            sys.stdout.write( 'Individual id "'+str(ind_id)+'" has '+str(len(barcode_clusters))+' barcode clusters ('+str(misc.percentage( sum([barcode_cluster.readPairCount for barcode_cluster in barcode_clusters]) ,self.analysisfolder.results.totalReadCount))+'% ot total read count):\n')
            
            
            types_this_individual = {}
            for barcode_cluster in barcode_clusters:
                try:             types_this_individual[barcode_cluster.in_allele].append(barcode_cluster)
                except KeyError: types_this_individual[barcode_cluster.in_allele]    =  [barcode_cluster]
            
            sys.stdout.write( '\t#bc:\t%trc:\t%bci:\t%rci:\twhat:\n')
            for type_of_cluster, list_of_clusters_with_type, tmp_junk in sorted([(type_of_cluster, list_of_clusters_with_type,sum([barcode_cluster.readPairCount for barcode_cluster in list_of_clusters_with_type])) for type_of_cluster, list_of_clusters_with_type in types_this_individual.iteritems()], key=operator.itemgetter(2), reverse=True):
            #for type_of_cluster, list_of_clusters_with_type in types_this_individual.iteritems():
                #print '   ',len(list_of_clusters_with_type),'barcode clusters with',type_of_cluster,'(',str(misc.percentage( sum([barcode_cluster.readPairCount for barcode_cluster in list_of_clusters_with_type]) ,self.analysisfolder.results.totalReadCount)),'% of total RC,'+str(misc.percentage( len(list_of_clusters_with_type),len(barcode_clusters)))+'% of bc in ind,',str(misc.percentage( sum([barcode_cluster.readPairCount for barcode_cluster in list_of_clusters_with_type]) ,sum([barcode_cluster.readPairCount for barcode_cluster in barcode_clusters]))),'% of rc in ind)'
                sys.stdout.write( '\t'+str(len(list_of_clusters_with_type))+'\t')
                sys.stdout.write( str(misc.percentage( sum([barcode_cluster.readPairCount for barcode_cluster in list_of_clusters_with_type]),self.analysisfolder.results.totalReadCount))+'\t')
                sys.stdout.write( str(misc.percentage( len(list_of_clusters_with_type),len(barcode_clusters)))+'\t')
                sys.stdout.write( str(misc.percentage( sum([barcode_cluster.readPairCount for barcode_cluster in list_of_clusters_with_type]) ,sum([barcode_cluster.readPairCount for barcode_cluster in barcode_clusters])))+'\t')
                sys.stdout.write(str( type_of_cluster)+'\n')

            sys.stdout.write( '\n')

if __name__ == "__main__": main()